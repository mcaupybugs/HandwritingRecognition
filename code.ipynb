{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitbasecondae0f52b00d66e4771b9f6f763f4d6dfb8",
   "display_name": "Python 3.6.10 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/written_name_train_v2.csv')\n",
    "valid = pd.read_csv('./data/written_name_validation_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method NDFrame.head of                 FILENAME       IDENTITY\n0        TRAIN_00001.jpg      BALTHAZAR\n1        TRAIN_00002.jpg          SIMON\n2        TRAIN_00003.jpg          BENES\n3        TRAIN_00004.jpg        LA LOVE\n4        TRAIN_00005.jpg         DAPHNE\n...                  ...            ...\n330956  TRAIN_330957.jpg          LENNY\n330957  TRAIN_330958.jpg        TIFFANY\n330958  TRAIN_330959.jpg  COUTINHO DESA\n330959  TRAIN_330960.jpg         MOURAD\n330960  TRAIN_330961.jpg        HELOISE\n\n[330961 rows x 2 columns]>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of train NaN: 565\nNumber of train NaN: 78\n"
    }
   ],
   "source": [
    "#Cleaning the data \n",
    "print(\"Number of train NaN:\",train['IDENTITY'].isnull().sum())\n",
    "print(\"Number of train NaN:\",valid['IDENTITY'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping NaN Values \n",
    "train.dropna(axis=0,inplace=True)\n",
    "valid.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for unreadable images \n",
    "unreadable = train[train['IDENTITY'] == 'UNREADABLE']\n",
    "unreadable.reset_index(inplace = True, drop=True)\n",
    "train = train[train['IDENTITY'] != 'UNREADABLE']\n",
    "valid = valid[valid['IDENTITY'] != 'UNREADABLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the lowercase to uppercase to maintain uniformity\n",
    "train['IDENTITY']=train['IDENTITY'].str.upper()\n",
    "valid['IDENTITY']=valid['IDENTITY'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reseting the index of elements\n",
    "train.reset_index(inplace=True,drop=True)\n",
    "valid.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING AND PREPARING THE IMAGES\n",
    "\n",
    "#Image loaded as grayscale and reshaped to 256 and 64\n",
    "#The width and height are cropped if they are greater than 256 and 64 respectively. If they are smaller, then the image is padded with white pixels. Finally the image is rotated clockwise to bring the image shape to (x, y).\n",
    "\n",
    "\n",
    "#The image is then normalized to range [0, 1]\n",
    "\n",
    "def preprocess(img):\n",
    "    (h,w)=img.shape\n",
    "    final_img = np.ones([64,256])*255 \n",
    "\n",
    "    if w>256:\n",
    "        img=img[:,:256]\n",
    "    \n",
    "    if h>64:\n",
    "        img = img[:64,:]\n",
    "\n",
    "    final_img[:h,:w] = img\n",
    "    return cv2.rotate(final_img,cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = 10000\n",
    "valid_size=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "for i in range(train_size):\n",
    "    img_dir = './data/train_v2/train/'+train.loc[i,'FILENAME']\n",
    "    image = cv2.imread(img_dir,cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image/255\n",
    "    train_x.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = []\n",
    "for i in range(valid_size):\n",
    "        img_dir = './data/validation_v2/validation/'+valid.loc[i,'FILENAME']\n",
    "        image = cv2.imread(img_dir,cv2.IMREAD_GRAYSCALE)\n",
    "        image = preprocess(image)\n",
    "        image = image/255\n",
    "        valid_x.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the array\n",
    "train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
    "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"
   ]
  }
 ]
}